{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eleanarey/ProgramingPractices/blob/main/implementacion_de_vit_jax_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MYot7DJh9kk"
      },
      "source": [
        "See code at https://github.com/google-research/vision_transformer/\n",
        "\n",
        "See papers at\n",
        "\n",
        "- Vision Transformer: https://arxiv.org/abs/2010.11929\n",
        "- MLP-Mixer: https://arxiv.org/abs/2105.01601\n",
        "- How to train your ViT: https://arxiv.org/abs/2106.10270\n",
        "- When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations: https://arxiv.org/abs/2106.01548\n",
        "\n",
        "This Colab allows you to run the [JAX](https://jax.readthedocs.org) implementation of the Vision Transformer.\n",
        "\n",
        "If you just want to load a pre-trained checkpoint from a large repository and\n",
        "directly use it for inference, you probably want to go [this Colab](https://colab.research.google.com/github/google-research/vision_transformer/blob/main/vit_jax_augreg.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhZm0kpPpH6"
      },
      "source": [
        "##### Copyright 2021 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfe6jvTCo1yQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KfmzfvFxPuk7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOVCm4CnP1Do"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/vision_transformer/blob/main/vit_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyD76dm5JaeW"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Needs to be executed once in every VM.\n",
        "\n",
        "The cell below downloads the code from Github and install necessary dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "zZvI8OXt78sj",
        "outputId": "e0f04bb2-6de5-42e4-fd0d-5f9a13ada85c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f35305e02f04>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Montar Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# \"comentamos esta celda y añadimos la siguiente\" drive.mount('/gdrive')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Ruta al archivo ZIP en Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# \"comentamos esta celda y añadimos la siguiente\" root = '/gdrive/My Drive/vision_transformer_colab'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ],
      "source": [
        "#@markdown Select whether you would like to store data in your personal drive.\n",
        "#@markdown\n",
        "#@markdown If you select **yes**, you will need to authorize Colab to access\n",
        "#@markdown your personal drive\n",
        "#@markdown\n",
        "#@markdown If you select **no**, then any changes you make will diappear when\n",
        "#@markdown this Colab's VM restarts after some time of inactivity...\n",
        "use_gdrive = 'yes'  #@param [\"yes\", \"no\"]\n",
        "\n",
        "\n",
        "if use_gdrive == 'yes':\n",
        "  from google.colab import drive\n",
        "  # Montar Google Drive\n",
        "  # \"comentamos esta celda y añadimos la siguiente\" drive.mount('/gdrive')\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  # Ruta al archivo ZIP en Google Drive\n",
        "  # \"comentamos esta celda y añadimos la siguiente\" root = '/gdrive/My Drive/vision_transformer_colab'\n",
        "  root = \"/content/drive/MyDrive/Colab_Notebooks\"\n",
        "  import os\n",
        "  if not os.path.isdir(root):\n",
        "    os.mkdir(root)\n",
        "  os.chdir(root)\n",
        "  print(f'\\nChanged CWD to \"{root}\"')\n",
        "else:\n",
        "  from IPython import display\n",
        "  display.display(display.HTML(\n",
        "      '<h1 style=\"color:red\">CHANGES NOT PERSISTED</h1>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeEy6gN71CDa"
      },
      "outputs": [],
      "source": [
        "# Clone repository and pull latest changes.\n",
        "'''![ -d vision_transformer ] || git clone --depth=1 https://github.com/google-research/vision_transformer\n",
        "!cd vision_transformer && git pull'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCN4d-GQJdU4"
      },
      "outputs": [],
      "source": [
        "# Colab already includes most of the dependencies, so we only install the delta:\n",
        "!pip install einops>=0.3.0 ml-collections>=0.1.0 aqtp>=0.2.0 clu>=0.0.3 git+https://github.com/google/flaxformer tensorflow-text>=2.9.0\n",
        "\n",
        "#añadido\n",
        "!pip install opencv-python-headless\n",
        "!pip install imagehash\n",
        "\n",
        "\n",
        "\n",
        "#!pip install -qr vision_transformer/vit_jax/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLBTSXuNjK6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBQnIvP73igZ"
      },
      "source": [
        "Los datos que consltan en esta sección provienen de un bucket de Google Cloud Storage. En este caso, las líneas de código con el comando gsutil están accediendo a recursos almacenados en los buckets [gs://vit_models/](https://) y [gs://mixer_models/](https://).\n",
        "\n",
        "### ¿Qué son estos buckets?\n",
        "Un bucket es un contenedor en Google Cloud Storage donde se almacenan archivos o datos de manera organizada.\n",
        "\n",
        "En este caso:\n",
        "\n",
        "[gs://vit_models/](https://): Almacena modelos preentrenados de Vision Transformer (ViT).\n",
        "Por ejemplo:\n",
        "Modelos entrenados en ImageNet (imagenet*).\n",
        "Modelos SAM (Segment Anything Models).\n",
        "\n",
        "[gs://mixer_models/](https://): Almacena modelos relacionados con MLP-Mixer, otra arquitectura para visión por computadora.\n",
        "\n",
        "## Explicación de los comandos:\n",
        "\n",
        "### !gsutil ls -lh gs://vit_models/imagenet*:\n",
        "Lista todos los modelos preentrenados de ViT que se entrenaron usando el dataset ImageNet.\n",
        "Muestra información como tamaño del archivo y la ruta.\n",
        "\n",
        "### !gsutil ls -lh gs://vit_models/sam:\n",
        "Lista modelos de SAM disponibles en ese bucket.\n",
        "\n",
        "### !gsutil ls -lh gs://mixer_models/*:\n",
        "Lista los modelos de MLP-Mixer disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcnlJF7FKTfD"
      },
      "outputs": [],
      "source": [
        "# Shows all available pre-trained models.\n",
        "!gsutil ls -lh gs://vit_models/imagenet*\n",
        "!gsutil ls -lh gs://vit_models/sam\n",
        "!gsutil ls -lh gs://mixer_models/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ztOhq_fzZyO"
      },
      "outputs": [],
      "source": [
        "# Download a pre-trained model.\n",
        "\n",
        "# Note: you can really choose any of the above, but this Colab has been tested\n",
        "# with the models of below selection...\n",
        "model_name = 'ViT-B_32'  #@param [\"ViT-B_32\", \"Mixer-B_16\"]\n",
        "\n",
        "if model_name.startswith('ViT'):\n",
        "  ![ -e \"$model_name\".npz ] || gsutil cp gs://vit_models/imagenet21k/\"$model_name\".npz .\n",
        "if model_name.startswith('Mixer'):\n",
        "  ![ -e \"$model_name\".npz ] || gsutil cp gs://mixer_models/imagenet21k/\"$model_name\".npz .\n",
        "\n",
        "import os\n",
        "assert os.path.exists(f'{model_name}.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EzOChfJeVrU"
      },
      "outputs": [],
      "source": [
        "# Google Colab \"TPU\" runtimes are configured in \"2VM mode\", meaning that JAX\n",
        "# cannot see the TPUs because they're not directly attached. Instead we need to\n",
        "# setup JAX to communicate with a second machine that has the TPUs attached.\n",
        "import os\n",
        "if 'google.colab' in str(get_ipython()) and 'COLAB_TPU_ADDR' in os.environ:\n",
        "  import jax\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()\n",
        "  print('Connected to TPU.')\n",
        "else:\n",
        "  print('No TPU detected. Can be changed under \"Runtime/Change runtime type\".')\n",
        "#Se incluyen estas lineas para explicar y corregir el error\n",
        "#¿Por qué aparece \"No TPU detected\"?\n",
        "#Esto ocurre porque el entorno de ejecución actual no tiene configurado el uso de un TPU. Probablemente estás ejecutando el Colab en un entorno estándar (CPU o GPU).\n",
        "#Para activar un TPU en Google Colab se debe cambiar el tipo de entorno de ejecución:\n",
        "#En el menú superior de Colab:\n",
        "#Ve a \"Runtime\" > \"Change runtime type\".\n",
        "#En \"Hardware accelerator\", selecciona TPU. Haz clic en \"Save\" y reinicia el entorno\n",
        "#Después de cambiar a TPU, Colab asignará un TPU y configurará la variable de entorno COLAB_TPU_ADDR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L03A_93y-Q8x"
      },
      "outputs": [],
      "source": [
        "!echo $COLAB_TPU_ADDR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtZOoPQm-em_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.environ.get('COLAB_TPU_ADDR'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIUF7guM_-Z7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igqZ6qYNeHWo"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "import flax\n",
        "import jax\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import tqdm\n",
        "\n",
        "logging.set_verbosity(logging.INFO)\n",
        "\n",
        "# Shows the number of available devices.\n",
        "# In a CPU/GPU runtime this will be a single device.\n",
        "# In a TPU runtime this will be 8 cores.\n",
        "jax.local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TuMn31fNj0T"
      },
      "outputs": [],
      "source": [
        "# Open some code files in a split editor on the right.\n",
        "# You can open more files in the file tab on the left.\n",
        "\n",
        "# Si ejecutas este código en un Colab, verás los archivos abiertos en la parte derecha. Desde allí puedes:\n",
        "# Leer el contenido de los archivos para entender cómo está estructurado el proyecto.\n",
        "# Realizar ediciones rápidas en el código.\n",
        "# Guardar los cambios en tu sesión de Colab o descargar los archivos modificados.\n",
        "\n",
        "from google.colab import files\n",
        "files.view('vision_transformer/vit_jax/configs/common.py')\n",
        "files.view('vision_transformer/vit_jax/configs/models.py')\n",
        "files.view('vision_transformer/vit_jax/checkpoint.py')\n",
        "files.view('vision_transformer/vit_jax/input_pipeline.py')\n",
        "files.view('vision_transformer/vit_jax/models.py')\n",
        "files.view('vision_transformer/vit_jax/train.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sjN0_b-YbaHu"
      },
      "outputs": [],
      "source": [
        "# Import files from repository.\n",
        "# Updating the files in the editor on the right will immediately update the\n",
        "# modules by re-importing them.\n",
        "\n",
        "import sys\n",
        "if './vision_transformer' not in sys.path:\n",
        "  sys.path.append('./vision_transformer')\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from vit_jax import checkpoint\n",
        "from vit_jax import input_pipeline\n",
        "from vit_jax import utils\n",
        "from vit_jax import models\n",
        "from vit_jax import train\n",
        "from vit_jax.configs import common as common_config\n",
        "from vit_jax.configs import models as models_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GojydzsXgknd"
      },
      "outputs": [],
      "source": [
        "# Helper functions for images.\n",
        "\n",
        "labelnames = dict(\n",
        "  # https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "  cifar10=('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'),\n",
        "  # https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "  cifar100=('apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm')\n",
        ")\n",
        "def make_label_getter(dataset):\n",
        "  \"\"\"Returns a function converting label indices to names.\"\"\"\n",
        "  def getter(label):\n",
        "    if dataset in labelnames:\n",
        "      return labelnames[dataset][label]\n",
        "    return f'label={label}'\n",
        "  return getter\n",
        "\n",
        "def show_img(img, ax=None, title=None):\n",
        "  \"\"\"Shows a single image.\"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  ax.imshow(img[...])\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  if title:\n",
        "    ax.set_title(title)\n",
        "\n",
        "def show_img_grid(imgs, titles):\n",
        "  \"\"\"Shows a grid of images.\"\"\"\n",
        "  n = int(np.ceil(len(imgs)**.5))\n",
        "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
        "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
        "    img = (img + 1) / 2  # Denormalize\n",
        "    show_img(img, axs[i // n][i % n], title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZfK1vIIMmFz"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSAVpYtP5VaE"
      },
      "outputs": [],
      "source": [
        "dataset = 'cifar10'\n",
        "batch_size = 512\n",
        "config = common_config.with_dataset(common_config.get_config(), dataset)\n",
        "config.batch = batch_size\n",
        "config.pp.crop = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruzdzpsMNhGm"
      },
      "outputs": [],
      "source": [
        "# For details about setting up datasets, see input_pipeline.py on the right.\n",
        "ds_train = input_pipeline.get_data_from_tfds(config=config, mode='train')\n",
        "ds_test = input_pipeline.get_data_from_tfds(config=config, mode='test')\n",
        "num_classes = input_pipeline.get_dataset_info(dataset, 'train')['num_classes']\n",
        "del config  # Only needed to instantiate datasets.\n",
        "\n",
        "'''For The error message FailedPreconditionError:\n",
        "ioctl failed; [0000:00:04.0 PE0 C0 MC-1 TN0] Failed to set number of simple DMA addresses\n",
        "PLEASE SET THE TPU TO GPU IS AN RESOURCE AVAILABILITY ERROR\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c-LfxOJdj8_"
      },
      "outputs": [],
      "source": [
        "# Fetch a batch of test images for illustration purposes.\n",
        "batch = next(iter(ds_test.as_numpy_iterator()))\n",
        "# Note the shape : [num_local_devices, local_batch_size, h, w, c]\n",
        "batch['image'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL0jQRBCgeJA"
      },
      "outputs": [],
      "source": [
        "# Show some images with their labels.\n",
        "images, labels = batch['image'][0][:9], batch['label'][0][:9]\n",
        "titles = map(make_label_getter(dataset), labels.argmax(axis=1))\n",
        "show_img_grid(images, titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFqi3h7yMEsB"
      },
      "outputs": [],
      "source": [
        "# Same as above, but with train images.\n",
        "# Note how images are cropped/scaled differently.\n",
        "# Check out input_pipeline.get_data() in the editor at your right to see how the\n",
        "# images are preprocessed differently.\n",
        "batch = next(iter(ds_train.as_numpy_iterator()))\n",
        "images, labels = batch['image'][0][:9], batch['label'][0][:9]\n",
        "titles = map(make_label_getter(dataset), labels.argmax(axis=1))\n",
        "show_img_grid(images, titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehzbRTSN20E5"
      },
      "source": [
        "### Load pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kIeQWuyf4Ga"
      },
      "outputs": [],
      "source": [
        "model_config = models_config.MODEL_CONFIGS[model_name]\n",
        "model_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMKr-4nK3DlT"
      },
      "outputs": [],
      "source": [
        "# Load model definition & initialize random parameters.\n",
        "# This also compiles the model to XLA (takes some minutes the first time).\n",
        "if model_name.startswith('Mixer'):\n",
        "  model = models.MlpMixer(num_classes=num_classes, **model_config)\n",
        "else:\n",
        "  model = models.VisionTransformer(num_classes=num_classes, **model_config)\n",
        "variables = jax.jit(lambda: model.init(\n",
        "    jax.random.PRNGKey(0),\n",
        "    # Discard the \"num_local_devices\" dimension of the batch for initialization.\n",
        "    batch['image'][0, :1],\n",
        "    train=False,\n",
        "), backend='cpu')()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIXjOEDkvAWM"
      },
      "outputs": [],
      "source": [
        "# Load and convert pretrained checkpoint.\n",
        "# This involves loading the actual pre-trained model results, but then also also\n",
        "# modifying the parameters a bit, e.g. changing the final layers, and resizing\n",
        "# the positional embeddings.\n",
        "# For details, refer to the code and to the methods of the paper.\n",
        "params = checkpoint.load_pretrained(\n",
        "    pretrained_path=f'{model_name}.npz',\n",
        "    init_params=variables['params'],\n",
        "    model_config=model_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQVKzhaR8o-J"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB6ywRTY-LOa"
      },
      "outputs": [],
      "source": [
        "# So far, all our data is in the host memory. Let's now replicate the arrays\n",
        "# into the devices.\n",
        "# This will make every array in the pytree params become a ShardedDeviceArray\n",
        "# that has the same data replicated across all local devices.\n",
        "# For TPU it replicates the params in every core.\n",
        "# For a single GPU this simply moves the data onto the device.\n",
        "# For CPU it simply creates a copy.\n",
        "params_repl = flax.jax_utils.replicate(params)\n",
        "print('params.cls:', type(params['head']['bias']).__name__,\n",
        "      params['head']['bias'].shape)\n",
        "print('params_repl.cls:', type(params_repl['head']['bias']).__name__,\n",
        "      params_repl['head']['bias'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_unNxEZAK0Cu"
      },
      "outputs": [],
      "source": [
        "# Then map the call to our model's forward pass onto all available devices.\n",
        "vit_apply_repl = jax.pmap(lambda params, inputs: model.apply(\n",
        "    dict(params=params), inputs, train=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgjFBUQ88p4z"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(params_repl):\n",
        "  \"\"\"Returns accuracy evaluated on the test set.\"\"\"\n",
        "  good = total = 0\n",
        "  steps = input_pipeline.get_dataset_info(dataset, 'test')['num_examples'] // batch_size\n",
        "  for _, batch in zip(tqdm.trange(steps), ds_test.as_numpy_iterator()):\n",
        "    predicted = vit_apply_repl(params_repl, batch['image'])\n",
        "    is_same = predicted.argmax(axis=-1) == batch['label'].argmax(axis=-1)\n",
        "    good += is_same.sum()\n",
        "    total += len(is_same.flatten())\n",
        "  return good / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qc7j0lv-F6-"
      },
      "outputs": [],
      "source": [
        "# Random performance without fine-tuning.\n",
        "get_accuracy(params_repl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxMdU_e5NeoT"
      },
      "source": [
        "### Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI62dexw8mGo"
      },
      "outputs": [],
      "source": [
        "# 100 Steps take approximately 15 minutes in the TPU runtime.\n",
        "total_steps = 100\n",
        "warmup_steps = 5\n",
        "decay_type = 'cosine'\n",
        "grad_norm_clip = 1\n",
        "# This controls in how many forward passes the batch is split. 8 works well with\n",
        "# a TPU runtime that has 8 devices. 64 should work on a GPU. You can of course\n",
        "# also adjust the batch_size above, but that would require you to adjust the\n",
        "# learning rate accordingly.\n",
        "accum_steps = 8\n",
        "base_lr = 0.03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzlfREb1ZHBY"
      },
      "outputs": [],
      "source": [
        "# Check out train.make_update_fn in the editor on the right side for details.\n",
        "lr_fn = utils.create_learning_rate_schedule(total_steps, base_lr, decay_type, warmup_steps)\n",
        "# We use a momentum optimizer that uses half precision for state to save\n",
        "# memory. It als implements the gradient clipping.\n",
        "tx = optax.chain(\n",
        "    optax.clip_by_global_norm(grad_norm_clip),\n",
        "    optax.sgd(\n",
        "        learning_rate=lr_fn,\n",
        "        momentum=0.9,\n",
        "        accumulator_dtype='bfloat16',\n",
        "    ),\n",
        ")\n",
        "update_fn_repl = train.make_update_fn(\n",
        "    apply_fn=model.apply, accum_steps=accum_steps, tx=tx)\n",
        "opt_state = tx.init(params)\n",
        "opt_state_repl = flax.jax_utils.replicate(opt_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTU7OmgjHb-G"
      },
      "outputs": [],
      "source": [
        "# Initialize PRNGs for dropout.\n",
        "update_rng_repl = flax.jax_utils.replicate(jax.random.PRNGKey(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKn4IfUWHWPk"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "lrs = []\n",
        "# Completes in ~20 min on the TPU runtime.\n",
        "for step, batch in zip(\n",
        "    tqdm.trange(1, total_steps + 1),\n",
        "    ds_train.as_numpy_iterator(),\n",
        "):\n",
        "\n",
        "  params_repl, opt_state_repl, loss_repl, update_rng_repl = update_fn_repl(\n",
        "      params_repl, opt_state_repl, batch, update_rng_repl)\n",
        "  losses.append(loss_repl[0])\n",
        "  lrs.append(lr_fn(step))\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.figure()\n",
        "plt.plot(lrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJhKAMhMI2D6"
      },
      "outputs": [],
      "source": [
        "# Should be ~96.7% for Mixer-B/16 or 97.7% for ViT-B/32 on CIFAR10 (both @224)\n",
        "get_accuracy(params_repl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-wIdj_qnbIM"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrOSyiBsE-N-"
      },
      "outputs": [],
      "source": [
        "# Download a pre-trained model.\n",
        "\n",
        "if model_name.startswith('Mixer'):\n",
        "  # Download model trained on imagenet2012\n",
        "  ![ -e \"$model_name\"_imagenet2012.npz ] || gsutil cp gs://mixer_models/imagenet1k/\"$model_name\".npz \"$model_name\"_imagenet2012.npz\n",
        "  model = models.MlpMixer(num_classes=1000, **model_config)\n",
        "else:\n",
        "  # Download model pre-trained on imagenet21k and fine-tuned on imagenet2012.\n",
        "  ![ -e \"$model_name\"_imagenet2012.npz ] || gsutil cp gs://vit_models/imagenet21k+imagenet2012/\"$model_name\".npz \"$model_name\"_imagenet2012.npz\n",
        "  model = models.VisionTransformer(num_classes=1000, **model_config)\n",
        "\n",
        "import os\n",
        "assert os.path.exists(f'{model_name}_imagenet2012.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE7BoGkyoY7X"
      },
      "outputs": [],
      "source": [
        "# Load and convert pretrained checkpoint.\n",
        "params = checkpoint.load(f'{model_name}_imagenet2012.npz')\n",
        "params['pre_logits'] = {}  # Need to restore empty leaf for Flax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3TTypN0gkwO"
      },
      "outputs": [],
      "source": [
        "# Get imagenet labels.\n",
        "!wget https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\n",
        "imagenet_labels = dict(enumerate(open('ilsvrc2012_wordnet_lemmas.txt')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQwomPOopDlr"
      },
      "outputs": [],
      "source": [
        "# Get a random picture with the correct dimensions.\n",
        "resolution = 224 if model_name.startswith('Mixer') else 384\n",
        "!wget https://picsum.photos/$resolution -O picsum.jpg\n",
        "import PIL\n",
        "img = PIL.Image.open('picsum.jpg')\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrvwNAGJshzb"
      },
      "outputs": [],
      "source": [
        "# Predict on a batch with a single item (note very efficient TPU usage...)\n",
        "logits, = model.apply(dict(params=params), (np.array(img) / 128 - 1)[None, ...], train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64hwCdaehs42"
      },
      "outputs": [],
      "source": [
        "preds = np.array(jax.nn.softmax(logits))\n",
        "for idx in preds.argsort()[:-11:-1]:\n",
        "  print(f'{preds[idx]:.5f} : {imagenet_labels[idx]}', end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnjAqrnNInCI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def is_blurry(image_path, threshold=100):\n",
        "    \"\"\"\n",
        "    Detecta si una imagen está borrosa usando el método Laplaciano.\n",
        "\n",
        "    Parámetros:\n",
        "        image_path (str): Ruta a la imagen.\n",
        "        threshold (float): Umbral de varianza. Imágenes con varianza menor son consideradas borrosas.\n",
        "\n",
        "    Retorna:\n",
        "        bool: True si la imagen está borrosa, False si no lo está.\n",
        "        float: Varianza del Laplaciano.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"La imagen {image_path} no existe.\")\n",
        "\n",
        "    # Cargar la imagen en escala de grises\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"No se pudo leer la imagen {image_path}.\")\n",
        "\n",
        "    # Aplicar el filtro Laplaciano y calcular su varianza\n",
        "    laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
        "\n",
        "    # Retornar si está borrosa según el umbral\n",
        "    return laplacian_var < threshold, laplacian_var\n",
        "\n",
        "def detect_blurry_images_in_directory(directory, threshold=100):\n",
        "    \"\"\"\n",
        "    Detecta imágenes borrosas en un directorio.\n",
        "\n",
        "    Parámetros:\n",
        "        directory (str): Ruta al directorio de imágenes.\n",
        "        threshold (float): Umbral de varianza para determinar si una imagen está borrosa.\n",
        "\n",
        "    Retorna:\n",
        "        List[Tuple[str, float, bool]]: Lista con la ruta, varianza y estado (borrosa o no) de cada imagen.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for filename in os.listdir(directory):\n",
        "        image_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(image_path):\n",
        "            try:\n",
        "                is_blurred, variance = is_blurry(image_path, threshold)\n",
        "                results.append((filename, variance, is_blurred))\n",
        "            except Exception as e:\n",
        "                print(f\"Error procesando {filename}: {e}\")\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iGTp9OSWoWr"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "dataset, info = tfds.load(\"cifar10\", with_info=True, as_supervised=True)\n",
        "np.savez_compressed(\"cifar10_images.npz\", images=[img.numpy() for img, _ in dataset['train']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MKvEStEa4FV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Función para detectar imágenes borrosas en un directorio\n",
        "def detect_blurry_images_in_directory(directory_path, threshold=400):\n",
        "    \"\"\"\n",
        "    Detecta imágenes borrosas en un directorio.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        threshold (float): Umbral de varianza para determinar si una imagen está borrosa.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, float, bool]]: Nombre del archivo, varianza y estado (borrosa o no).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(image_path):  # Verificar si es un archivo\n",
        "            # Cargar la imagen\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                print(f\"No se pudo leer la imagen: {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Convertir a escala de grises\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Aplicar filtro Laplaciano\n",
        "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "            is_blurred = laplacian_var < threshold\n",
        "            results.append((filename, laplacian_var, is_blurred))\n",
        "    return results\n",
        "\n",
        "# 2. Mostrar una imagen con Matplotlib\n",
        "def show_image(image_path, title):\n",
        "    \"\"\"\n",
        "    Muestra una imagen con Matplotlib.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Ruta de la imagen.\n",
        "        title (str): Título para mostrar en la gráfica.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# 3. Mostrar imágenes en formato grid\n",
        "def show_img_grid(images, titles, grid_size=(3, 3), figsize=(10, 10)):\n",
        "    \"\"\"\n",
        "    Muestra las imágenes en una cuadrícula.\n",
        "\n",
        "    Args:\n",
        "        images (list): Lista de rutas de imágenes.\n",
        "        titles (list): Lista de títulos para cada imagen.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula (filas, columnas).\n",
        "        figsize (tuple): Tamaño de la figura.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(*grid_size, figsize=figsize)\n",
        "    axes = axes.ravel()\n",
        "    for idx, (img_path, title) in enumerate(zip(images, titles)):\n",
        "        if idx >= len(axes):\n",
        "            break\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(title)\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 4. Aplicación principal: Analizar un directorio de imágenes\n",
        "def analyze_blurry_images_in_directory(directory_path, threshold=400, grid_size=(3, 3)):\n",
        "    \"\"\"\n",
        "    Analiza las imágenes en un directorio para detectar imágenes borrosas y mostrarlas en un grid.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        threshold (float): Umbral de varianza para detectar imágenes borrosas.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula para mostrar imágenes.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Detectar imágenes borrosas\n",
        "    blurry_results = detect_blurry_images_in_directory(directory_path, threshold)\n",
        "    num_b_blurry = sum(1 for _, _, is_blurred in blurry_results if is_blurred)\n",
        "        # Informe general\n",
        "    print(f\"\\nResumen del análisis:\")\n",
        "    print(f\"Total de imágenes analizadas: {len(blurry_results)}\")\n",
        "    print(f\"Total de imágenes borrosas detectadas: {num_b_blurry}\")\n",
        "    print(f\"Imágenes nítidas: {len(blurry_results) - num_b_blurry}\")\n",
        "\n",
        "    # Preparar imágenes para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for filename, var, blurred in blurry_results[:grid_size[0] * grid_size[1]]:\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        selected_images.append(image_path)\n",
        "        status = \"BORROSA\" if blurred else \"NÍTIDA\"\n",
        "        titles.append(f\"{status}\\nVar: {var:.2f}\")\n",
        "\n",
        "    # Mostrar imágenes en formato grid\n",
        "    show_img_grid(selected_images, titles, grid_size)\n",
        "\n",
        "    # Preparar imágenes borrosas para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for filename, var, blurred in blurry_results:\n",
        "        if blurred:  # Solo incluir imágenes borrosas\n",
        "            image_path = os.path.join(directory_path, filename)\n",
        "            selected_images.append(image_path)\n",
        "            titles.append(f\"BORROSA\\nVar: {var:.2f}\")\n",
        "\n",
        "            # Detener si se alcanza el límite del grid\n",
        "            if len(selected_images) >= grid_size[0] * grid_size[1]:\n",
        "                break\n",
        "\n",
        "    # Mostrar imágenes borrosas en formato grid\n",
        "    if selected_images:\n",
        "        show_img_grid(selected_images, titles, grid_size)\n",
        "    else:\n",
        "        print(\"No se encontraron imágenes borrosas para mostrar.\")\n",
        "\n",
        "\n",
        "# 5. Ejecutar el análisis en un directorio\n",
        "directory_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/tiny-imagenet-200/tiny-imagenet-200/test/images\"  # Ruta al directorio de imágenes\n",
        "threshold = 400  # Ajusta el umbral según sea necesario\n",
        "analyze_blurry_images_in_directory(directory_path, threshold, grid_size=(5, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jJN_5x0WqoO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Función para cargar un archivo .npz\n",
        "def load_npz_file(file_path):\n",
        "    \"\"\"\n",
        "    Carga un archivo .npz y devuelve su contenido.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo .npz.\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con los datos almacenados en el archivo.\n",
        "    \"\"\"\n",
        "    data = np.load(file_path, allow_pickle=True)\n",
        "    print(f\"Claves disponibles en {file_path}: {list(data.keys())}\")\n",
        "    return data\n",
        "\n",
        "# 2. Función para detectar imágenes borrosas\n",
        "def detect_blurry_images_from_npz(images, threshold=400):\n",
        "    \"\"\"\n",
        "    Detecta imágenes borrosas en un array NumPy.\n",
        "\n",
        "    Args:\n",
        "        images (np.array): Array de imágenes.\n",
        "        threshold (float): Umbral de varianza para determinar si está borrosa.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float, bool]]: Índice, varianza y estado (borrosa o no).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for i, img in enumerate(images):\n",
        "        # Convertir imagen a escala de grises si tiene 3 canales\n",
        "        if len(img.shape) == 3 and img.shape[-1] == 3:\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = img\n",
        "\n",
        "        # Aplicar filtro Laplaciano\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        is_blurred = laplacian_var < threshold\n",
        "        results.append((i, laplacian_var, is_blurred))\n",
        "    return results\n",
        "\n",
        "# 3. Función para mostrar una imagen con Matplotlib\n",
        "def show_image(image, title):\n",
        "    \"\"\"\n",
        "    Muestra una imagen con Matplotlib.\n",
        "\n",
        "    Args:\n",
        "        image (np.array): Imagen en formato NumPy.\n",
        "        title (str): Título para mostrar en la gráfica.\n",
        "    \"\"\"\n",
        "    plt.imshow(image, cmap=\"gray\" if len(image.shape) == 2 else None)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# 4. Función para mostrar imágenes en formato grid\n",
        "def show_img_grid(images, titles, grid_size=(3, 3), figsize=(10, 10)):\n",
        "    \"\"\"\n",
        "    Muestra las imágenes en una cuadrícula.\n",
        "\n",
        "    Args:\n",
        "        images (list): Lista o array de imágenes.\n",
        "        titles (list): Lista de títulos para cada imagen.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula (filas, columnas).\n",
        "        figsize (tuple): Tamaño de la figura.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(*grid_size, figsize=figsize)\n",
        "    axes = axes.ravel()\n",
        "    for idx, (img, title) in enumerate(zip(images, titles)):\n",
        "        if idx >= len(axes):\n",
        "            break\n",
        "        axes[idx].imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
        "        axes[idx].set_title(title)\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 5. Análisis principal con integración de grid\n",
        "def analyze_blurry_images(npz_file_path, image_key, threshold=400, grid_size=(3, 3)):\n",
        "    \"\"\"\n",
        "    Analiza las imágenes en un archivo .npz para detectar imágenes borrosas y las muestra en un grid.\n",
        "\n",
        "    Args:\n",
        "        npz_file_path (str): Ruta al archivo .npz.\n",
        "        image_key (str): Clave para acceder a las imágenes en el archivo.\n",
        "        threshold (float): Umbral de varianza para detectar imágenes borrosas.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula para mostrar imágenes.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Cargar datos del archivo .npz\n",
        "    data = load_npz_file(npz_file_path)\n",
        "\n",
        "    # Obtener las imágenes\n",
        "    if image_key not in data:\n",
        "        print(f\"Clave '{image_key}' no encontrada en el archivo.\")\n",
        "        return\n",
        "    images = data[image_key]\n",
        "\n",
        "    # Detectar imágenes borrosas\n",
        "    blurry_results = detect_blurry_images_from_npz(images, threshold)\n",
        "    num_b_blurry = sum(1 for _, _, is_blurred in blurry_results if is_blurred)\n",
        "    print(f\"Total de imágenes analizadas: {len(images)}\")\n",
        "    print(f\"Total de imágenes borrosas detectadas: {num_b_blurry}\")\n",
        "    print(f\"Imágenes nítidas: {len(images) - num_b_blurry}\")\n",
        "\n",
        "    # Preparar imágenes para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for idx, var, blurred in blurry_results[:grid_size[0] * grid_size[1]]:\n",
        "        selected_images.append(images[idx])\n",
        "        status = \"BORROSA\" if blurred else \"NÍTIDA\"\n",
        "        titles.append(f\"{status}\\nVar: {var:.2f}\")\n",
        "\n",
        "    # Mostrar imágenes en formato grid\n",
        "    show_img_grid(selected_images, titles, grid_size)\n",
        "\n",
        "    # Preparar imágenes borrosas para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for idx, var, blurred in blurry_results:\n",
        "        if blurred:  # Solo incluir imágenes borrosas\n",
        "            selected_images.append(images[idx])\n",
        "            titles.append(f\"BORROSA\\nVar: {var:.2f}\")\n",
        "\n",
        "            # Detener si se alcanza el límite del grid\n",
        "            if len(selected_images) >= grid_size[0] * grid_size[1]:\n",
        "                break\n",
        "\n",
        "    # Mostrar imágenes borrosas en formato grid\n",
        "    if selected_images:\n",
        "        show_img_grid(selected_images, titles, grid_size)\n",
        "    else:\n",
        "        print(\"No se encontraron imágenes borrosas para mostrar.\")\n",
        "\n",
        "\n",
        "# 6. Ejecutar el análisis\n",
        "npz_file_path = \"cifar10_images.npz\"\n",
        "image_key = \"images\"\n",
        "threshold = 400  # Ajusta el umbral según sea necesario\n",
        "analyze_blurry_images(npz_file_path, image_key, threshold, grid_size=(5, 5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us7h3kDBc2n2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "def analyze_thresholds(directory_path, thresholds):\n",
        "    \"\"\"\n",
        "    Analiza un directorio de imágenes para múltiples umbrales.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        thresholds (List[int]): Lista de valores de umbral a probar.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    results_per_threshold = {}\n",
        "    for threshold in thresholds:\n",
        "        print(f\"\\nAnalizando con umbral = {threshold}\")\n",
        "        blurry_results = detect_blurry_images_in_directory(directory_path, threshold)\n",
        "        num_b_blurry = sum(1 for _, _, is_blurred in blurry_results if is_blurred)\n",
        "        results_per_threshold[threshold] = num_b_blurry\n",
        "        print(f\"Imágenes borrosas detectadas: {num_b_blurry}\")\n",
        "\n",
        "    # Graficar los resultados\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(thresholds, [results_per_threshold[t] for t in thresholds], marker='o')\n",
        "    plt.title(\"Ajuste del Umbral\")\n",
        "    plt.xlabel(\"Umbral\")\n",
        "    plt.ylabel(\"Número de Imágenes Borrosas\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Prueba de umbrales\n",
        "directory_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/tiny-imagenet-200/tiny-imagenet-200/test/images\"\n",
        "thresholds = list(range(10, 200, 10))  # Prueba valores de 10 a 200 con pasos de 10\n",
        "#analyze_thresholds(directory_path, thresholds)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08tK0VKKsjvH"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def validate_threshold(directory_path, threshold):\n",
        "    \"\"\"\n",
        "    Muestra ejemplos de imágenes borrosas según un umbral.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        threshold (int): Umbral para detectar imágenes borrosas.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    blurry_results = detect_blurry_images_in_directory(directory_path, threshold)\n",
        "    print(f\"\\nValidando con umbral = {threshold}\")\n",
        "    print(f\"Imágenes borrosas detectadas: {sum(1 for _, _, is_blurred in blurry_results if is_blurred)}\")\n",
        "\n",
        "    # Mostrar hasta 5 imágenes borrosas\n",
        "    for filename, var, blurred in blurry_results[:5]:\n",
        "        if blurred:\n",
        "            image_path = os.path.join(directory_path, filename)\n",
        "            show_image(image_path, f\"BORROSA - Umbral: {threshold}, Varianza: {var:.2f}\")\n",
        "\n",
        "# Probar varios umbrales manualmente\n",
        "validate_threshold(directory_path, 50)   # Umbral bajo\n",
        "validate_threshold(directory_path, 100)  # Umbral medio\n",
        "validate_threshold(directory_path, 150)  # Umbral alto\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF_yxuvPstyk"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def generate_report(directory_path, thresholds):\n",
        "    \"\"\"\n",
        "    Genera un informe detallado de análisis de borrosidad para múltiples umbrales.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        thresholds (List[int]): Lista de valores de umbral a probar.\n",
        "\n",
        "    Returns:\n",
        "        dict: Resultados por cada umbral.\n",
        "    \"\"\"\n",
        "    report = {}\n",
        "    for threshold in thresholds:\n",
        "        blurry_results = detect_blurry_images_in_directory(directory_path, threshold)\n",
        "        num_b_blurry = sum(1 for _, _, is_blurred in blurry_results if is_blurred)\n",
        "        report[threshold] = {\n",
        "            \"total_images\": len(blurry_results),\n",
        "            \"blurry_images\": num_b_blurry,\n",
        "            \"non_blurry_images\": len(blurry_results) - num_b_blurry\n",
        "        }\n",
        "\n",
        "    # Mostrar informe\n",
        "    print(\"\\nInforme por umbral:\")\n",
        "    for threshold, data in report.items():\n",
        "        print(f\"Umbral {threshold}: {data['blurry_images']} borrosas, {data['non_blurry_images']} nítidas, {data['total_images']} totales\")\n",
        "\n",
        "    return report\n",
        "\n",
        "# Generar un informe detallado\n",
        "thresholds = [50, 100, 150]\n",
        "report = generate_report(directory_path, thresholds)\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjZUyoM3hNls"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "EXPERIMENTO 1 PARA DETECTAR DUPLICADOS, DESCARTADO POR NO DAR PRECISION\n",
        "'''\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Función para calcular descriptores (histogramas)\n",
        "def calculate_histogram(image_path):\n",
        "    \"\"\"\n",
        "    Calcula un histograma normalizado para una imagen.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Ruta de la imagen.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Histograma normalizado.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"No se pudo leer la imagen: {image_path}\")\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    histogram = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
        "    return histogram\n",
        "\n",
        "# 2. Función para calcular similitud\n",
        "def calculate_similarity(hist1, hist2):\n",
        "    \"\"\"\n",
        "    Calcula la similitud entre dos histogramas usando correlación.\n",
        "\n",
        "    Args:\n",
        "        hist1, hist2 (np.array): Histogramas de las imágenes.\n",
        "\n",
        "    Returns:\n",
        "        float: Similitud entre los histogramas.\n",
        "    \"\"\"\n",
        "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
        "\n",
        "# 3. Detectar imágenes duplicadas en un directorio\n",
        "def detect_duplicates(directory_path, similarity_threshold=0.95):\n",
        "    \"\"\"\n",
        "    Detecta imágenes duplicadas en un directorio.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        similarity_threshold (float): Umbral para considerar imágenes como duplicadas (0-1).\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: Lista de pares de imágenes duplicadas.\n",
        "    \"\"\"\n",
        "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
        "    histograms = {}\n",
        "    duplicates = []\n",
        "\n",
        "    for file in files:\n",
        "        image_path = os.path.join(directory_path, file)\n",
        "        histograms[file] = calculate_histogram(image_path)\n",
        "\n",
        "    checked = set()\n",
        "    for file1, hist1 in histograms.items():\n",
        "        for file2, hist2 in histograms.items():\n",
        "            if file1 != file2 and (file2, file1) not in checked:\n",
        "                similarity = calculate_similarity(hist1, hist2)\n",
        "                if similarity >= similarity_threshold:\n",
        "                    duplicates.append((file1, file2))\n",
        "                checked.add((file1, file2))\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# 4. Eliminar duplicados conservando solo una imagen\n",
        "def remove_duplicates(directory_path, duplicates):\n",
        "    \"\"\"\n",
        "    Elimina imágenes duplicadas, conservando solo una.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        duplicates (List[Tuple[str, str]]): Lista de pares de imágenes duplicadas.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    to_remove = set()\n",
        "    for file1, file2 in duplicates:\n",
        "        to_remove.add(file2)  # Conserva file1, elimina file2\n",
        "\n",
        "    for file in to_remove:\n",
        "        file_path = os.path.join(directory_path, file)\n",
        "        os.remove(file_path)\n",
        "        print(f\"Eliminado: {file_path}\")\n",
        "\n",
        "# 5. Visualizar un par de duplicados\n",
        "def show_duplicate_pair(directory_path, file1, file2):\n",
        "    \"\"\"\n",
        "    Muestra un par de imágenes duplicadas.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        file1, file2 (str): Nombres de los archivos duplicados.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    path1 = os.path.join(directory_path, file1)\n",
        "    path2 = os.path.join(directory_path, file2)\n",
        "\n",
        "    img1 = cv2.cvtColor(cv2.imread(path1), cv2.COLOR_BGR2RGB)\n",
        "    img2 = cv2.cvtColor(cv2.imread(path2), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img1)\n",
        "    plt.title(f\"Duplicado 1: {file1}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img2)\n",
        "    plt.title(f\"Duplicado 2: {file2}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# 6. Flujo completo para detectar y eliminar duplicados\n",
        "def process_duplicates(directory_path, similarity_threshold=0.95):\n",
        "    \"\"\"\n",
        "    Flujo completo para detectar y eliminar imágenes duplicadas.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        similarity_threshold (float): Umbral para considerar imágenes como duplicadas (0-1).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(f\"Analizando imágenes en: {directory_path}\")\n",
        "    duplicates = detect_duplicates(directory_path, similarity_threshold)\n",
        "    print(f\"Duplicados detectados: {len(duplicates)}\")\n",
        "    for file1, file2 in duplicates:\n",
        "        print(f\"Duplicado: {file1} y {file2}\")\n",
        "\n",
        "    # Visualizar los primeros duplicados\n",
        "    if duplicates:\n",
        "        print(\"\\nEjemplo de duplicados:\")\n",
        "        file1, file2 = duplicates[0]\n",
        "        show_duplicate_pair(directory_path, file1, file2)\n",
        "\n",
        "    # Eliminar duplicados\n",
        "    print(\"\\nEliminando duplicados...\")\n",
        "    #remove_duplicates(directory_path, duplicates)\n",
        "    print(\"Proceso completado.\")\n",
        "\n",
        "# 7. Ejecutar el flujo en un directorio\n",
        "directory_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/tiny-imagenet-200/tiny-imagenet-200/test/images\"\n",
        "similarity_threshold = 0.9  # Ajusta el umbral según sea necesario\n",
        "process_duplicates(directory_path, similarity_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrJ8e9ugzY1R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import imagehash\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_phash(image_path):\n",
        "    \"\"\"\n",
        "    Calcula el hash perceptual de una imagen.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Ruta de la imagen.\n",
        "\n",
        "    Returns:\n",
        "        str: Hash perceptual de la imagen.\n",
        "    \"\"\"\n",
        "    with Image.open(image_path) as img:\n",
        "        return str(imagehash.phash(img))\n",
        "\n",
        "def detect_duplicates_with_phash(directory_path):\n",
        "    \"\"\"\n",
        "    Detecta imágenes duplicadas en un directorio utilizando hashes perceptuales.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "\n",
        "    Returns:\n",
        "        dict: Duplicados detectados, mapeando hashes a listas de nombres de archivos.\n",
        "    \"\"\"\n",
        "    hash_map = defaultdict(list)\n",
        "    duplicates = []\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(image_path):\n",
        "            try:\n",
        "                phash = calculate_phash(image_path)\n",
        "                hash_map[phash].append(filename)\n",
        "            except Exception as e:\n",
        "                print(f\"Error procesando {filename}: {e}\")\n",
        "\n",
        "    # Filtrar hashes con más de un archivo (duplicados)\n",
        "    duplicates = {h: files for h, files in hash_map.items() if len(files) > 1}\n",
        "    return duplicates\n",
        "\n",
        "def show_duplicate_pairs(directory_path, duplicates):\n",
        "    \"\"\"\n",
        "    Muestra pares de imágenes duplicadas para comparación.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        duplicates (dict): Duplicados detectados mapeando hashes a listas de archivos.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for hash_val, files in duplicates.items():\n",
        "        if len(files) > 1:\n",
        "            print(f\"\\nComparando imágenes duplicadas para hash: {hash_val}\")\n",
        "            for i in range(1, len(files)):\n",
        "                file1 = os.path.join(directory_path, files[0])\n",
        "                file2 = os.path.join(directory_path, files[i])\n",
        "\n",
        "                # Cargar imágenes\n",
        "                img1 = cv2.cvtColor(cv2.imread(file1), cv2.COLOR_BGR2RGB)\n",
        "                img2 = cv2.cvtColor(cv2.imread(file2), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Mostrar imágenes lado a lado\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.imshow(img1)\n",
        "                plt.title(f\"Imagen 1: {files[0]}\")\n",
        "                plt.axis(\"off\")\n",
        "\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(img2)\n",
        "                plt.title(f\"Imagen 2: {files[i]}\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.show()\n",
        "\n",
        "def remove_duplicates(directory_path, duplicates):\n",
        "    \"\"\"\n",
        "    Elimina imágenes duplicadas conservando solo una por grupo.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        duplicates (dict): Duplicados detectados mapeando hashes a listas de archivos.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for hash_val, files in duplicates.items():\n",
        "        for file in files[1:]:  # Conserva solo el primero\n",
        "            file_path = os.path.join(directory_path, file)\n",
        "            os.remove(file_path)\n",
        "            print(f\"Eliminado duplicado: {file_path}\")\n",
        "\n",
        "# Ejecutar el flujo de trabajo\n",
        "directory_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/tiny-imagenet-200/tiny-imagenet-200/test/images\"\n",
        "duplicates = detect_duplicates_with_phash(directory_path)\n",
        "\n",
        "print(f\"Duplicados detectados: {len(duplicates)} grupos\")\n",
        "for hash_val, files in duplicates.items():\n",
        "    print(f\"Hash: {hash_val}, Archivos: {files}\")\n",
        "\n",
        "# Comparar visualmente duplicados\n",
        "show_duplicate_pairs(directory_path, duplicates)\n",
        "\n",
        "# Eliminar duplicados (opcional, descomenta para ejecutarlo)\n",
        "# remove_duplicates(directory_path, duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMkI2J1e4HYS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import imagehash\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "def calculate_phash(image_path):\n",
        "    \"\"\"\n",
        "    Calcula el hash perceptual de una imagen.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Ruta de la imagen.\n",
        "\n",
        "    Returns:\n",
        "        str: Hash perceptual de la imagen.\n",
        "    \"\"\"\n",
        "    with Image.open(image_path) as img:\n",
        "        return str(imagehash.phash(img))\n",
        "\n",
        "def detect_duplicates_with_phash(directory_path):\n",
        "    \"\"\"\n",
        "    Detecta imágenes duplicadas en un directorio utilizando hashes perceptuales.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "\n",
        "    Returns:\n",
        "        dict: Duplicados detectados, mapeando hashes a listas de nombres de archivos.\n",
        "    \"\"\"\n",
        "    hash_map = defaultdict(list)\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(image_path):\n",
        "            try:\n",
        "                phash = calculate_phash(image_path)\n",
        "                hash_map[phash].append(filename)\n",
        "            except Exception as e:\n",
        "                print(f\"Error procesando {filename}: {e}\")\n",
        "\n",
        "    # Filtrar hashes con más de un archivo (duplicados)\n",
        "    duplicates = {h: files for h, files in hash_map.items() if len(files) > 1}\n",
        "    return duplicates\n",
        "\n",
        "def show_duplicate_pairs(directory_path, duplicates):\n",
        "    \"\"\"\n",
        "    Muestra pares de imágenes duplicadas para comparación.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        duplicates (dict): Duplicados detectados mapeando hashes a listas de archivos.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for hash_val, files in duplicates.items():\n",
        "        if len(files) > 1:\n",
        "            print(f\"\\nComparando imágenes duplicadas para hash: {hash_val}\")\n",
        "            for i in range(1, len(files)):\n",
        "                file1 = os.path.join(directory_path, files[0])\n",
        "                file2 = os.path.join(directory_path, files[i])\n",
        "\n",
        "                # Cargar imágenes\n",
        "                img1 = cv2.cvtColor(cv2.imread(file1), cv2.COLOR_BGR2RGB)\n",
        "                img2 = cv2.cvtColor(cv2.imread(file2), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Mostrar imágenes lado a lado\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.imshow(img1)\n",
        "                plt.title(f\"Imagen 1: {files[0]}\")\n",
        "                plt.axis(\"off\")\n",
        "\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(img2)\n",
        "                plt.title(f\"Imagen 2: {files[i]}\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.show()\n",
        "\n",
        "def move_duplicates(directory_path, output_directory, duplicates):\n",
        "    \"\"\"\n",
        "    Mueve imágenes duplicadas a otro directorio conservando solo una por grupo.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        output_directory (str): Ruta al directorio de destino para duplicados.\n",
        "        duplicates (dict): Duplicados detectados mapeando hashes a listas de archivos.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    for hash_val, files in duplicates.items():\n",
        "        for file in files[1:]:  # Conserva solo el primero\n",
        "            source_path = os.path.join(directory_path, file)\n",
        "            destination_path = os.path.join(output_directory, file)\n",
        "            shutil.move(source_path, destination_path)\n",
        "            print(f\"Movido duplicado: {source_path} -> {destination_path}\")\n",
        "\n",
        "# Ejecutar el flujo de trabajo\n",
        "directory_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\"\n",
        "output_directory = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppDuplicados\"\n",
        "duplicates = detect_duplicates_with_phash(directory_path)\n",
        "\n",
        "print(f\"Duplicados detectados: {len(duplicates)} grupos\")\n",
        "for hash_val, files in duplicates.items():\n",
        "    print(f\"Hash: {hash_val}, Archivos: {files}\")\n",
        "\n",
        "# Comparar visualmente duplicados\n",
        "show_duplicate_pairs(directory_path, duplicates)\n",
        "\n",
        "# Mover duplicados\n",
        "move_duplicates(directory_path, output_directory, duplicates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bzkqi4nVbnh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MISMO CODIGO DE IMAGENES BORROSAS PERO CON EL CONJUNTO DE DATOS\n",
        "/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\n",
        "'''\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Función para detectar imágenes borrosas en un directorio\n",
        "def detect_blurry_images_in_directory(directory_path, threshold=100):\n",
        "    \"\"\"\n",
        "    Detecta imágenes borrosas en un directorio.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        threshold (float): Umbral de varianza para determinar si una imagen está borrosa.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, float, bool]]: Nombre del archivo, varianza y estado (borrosa o no).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(image_path):  # Verificar si es un archivo\n",
        "            # Cargar la imagen\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                print(f\"No se pudo leer la imagen: {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Convertir a escala de grises\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Aplicar filtro Laplaciano\n",
        "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "            is_blurred = laplacian_var < threshold\n",
        "            results.append((filename, laplacian_var, is_blurred))\n",
        "    return results\n",
        "\n",
        "# 2. Mostrar una imagen con Matplotlib\n",
        "def show_image(image_path, title):\n",
        "    \"\"\"\n",
        "    Muestra una imagen con Matplotlib.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Ruta de la imagen.\n",
        "        title (str): Título para mostrar en la gráfica.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# 3. Mostrar imágenes en formato grid\n",
        "def show_img_grid(images, titles, grid_size=(3, 3), figsize=(10, 10)):\n",
        "    \"\"\"\n",
        "    Muestra las imágenes en una cuadrícula.\n",
        "\n",
        "    Args:\n",
        "        images (list): Lista de rutas de imágenes.\n",
        "        titles (list): Lista de títulos para cada imagen.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula (filas, columnas).\n",
        "        figsize (tuple): Tamaño de la figura.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(*grid_size, figsize=figsize)\n",
        "    axes = axes.ravel()\n",
        "    for idx, (img_path, title) in enumerate(zip(images, titles)):\n",
        "        if idx >= len(axes):\n",
        "            break\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(title)\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 4. Aplicación principal: Analizar un directorio de imágenes\n",
        "def analyze_blurry_images_in_directory(directory_path, threshold=100, grid_size=(3, 3)):\n",
        "    \"\"\"\n",
        "    Analiza las imágenes en un directorio para detectar imágenes borrosas y mostrarlas en un grid.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        threshold (float): Umbral de varianza para detectar imágenes borrosas.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula para mostrar imágenes.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Detectar imágenes borrosas\n",
        "    blurry_results = detect_blurry_images_in_directory(directory_path, threshold)\n",
        "    num_b_blurry = sum(1 for _, _, is_blurred in blurry_results if is_blurred)\n",
        "        # Informe general\n",
        "    print(f\"\\nResumen del análisis:\")\n",
        "    print(f\"Total de imágenes analizadas: {len(blurry_results)}\")\n",
        "    print(f\"Total de imágenes borrosas detectadas: {num_b_blurry}\")\n",
        "    print(f\"Imágenes nítidas: {len(blurry_results) - num_b_blurry}\")\n",
        "\n",
        "\n",
        "    # Preparar imágenes para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for filename, var, blurred in blurry_results[:grid_size[0] * grid_size[1]]:\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        selected_images.append(image_path)\n",
        "        status = \"BORROSA\" if blurred else \"NÍTIDA\"\n",
        "        titles.append(f\"{status}\\nVar: {var:.2f}\")\n",
        "\n",
        "    # Mostrar imágenes en formato grid\n",
        "    show_img_grid(selected_images, titles, grid_size)\n",
        "\n",
        "    # Preparar imágenes borrosas para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for filename, var, blurred in blurry_results:\n",
        "        if blurred:  # Solo incluir imágenes borrosas\n",
        "            image_path = os.path.join(directory_path, filename)\n",
        "            selected_images.append(image_path)\n",
        "            titles.append(f\"BORROSA\\nVar: {var:.2f}\")\n",
        "\n",
        "            # Detener si se alcanza el límite del grid\n",
        "            if len(selected_images) >= grid_size[0] * grid_size[1]:\n",
        "                break\n",
        "\n",
        "    # Mostrar imágenes borrosas en formato grid\n",
        "    if selected_images:\n",
        "        show_img_grid(selected_images, titles, grid_size)\n",
        "    else:\n",
        "        print(\"No se encontraron imágenes borrosas para mostrar.\")\n",
        "\n",
        "\n",
        "# 5. Ejecutar el análisis en un directorio\n",
        "directory_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\"  # Ruta al directorio de imágenes\n",
        "threshold = 50  # Ajusta el umbral según sea necesario\n",
        "analyze_blurry_images_in_directory(directory_path, threshold, grid_size=(3, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqCib1UTqLf5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MISMO CODIGO DE IMAGENES BORROSAS PERO CON EL CONJUNTO DE DATOS Y MUEVE DE DIRECTORIO LAS IMAGENES BORROSAS\n",
        "/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\n",
        "'''\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Directorios de entrada y salida\n",
        "input_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppBorrosas_threshold_50\"\n",
        "output_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppBorrosas_threshold_20\"\n",
        "\n",
        "# Crear el directorio de salida si no existe\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# 1. Función para detectar imágenes borrosas y moverlas\n",
        "def detect_and_move_blurry_images(directory_path, output_directory, threshold=100):\n",
        "    \"\"\"\n",
        "    Detecta imágenes borrosas en un directorio y las mueve a otro directorio.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        output_directory (str): Ruta al directorio de destino para imágenes borrosas.\n",
        "        threshold (float): Umbral de varianza para determinar si una imagen está borrosa.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, float, bool]]: Nombre del archivo, varianza y estado (borrosa o no).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        image_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(image_path):  # Verificar si es un archivo\n",
        "            # Cargar la imagen\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                print(f\"No se pudo leer la imagen: {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Convertir a escala de grises\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Aplicar filtro Laplaciano\n",
        "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "            is_blurred = laplacian_var < threshold\n",
        "\n",
        "            # Si la imagen está borrosa, moverla al directorio de salida\n",
        "            if is_blurred:\n",
        "                shutil.move(image_path, os.path.join(output_directory, filename))\n",
        "                print(f\"Imagen borrosa detectada y movida: {filename} (Var: {laplacian_var:.2f})\")\n",
        "\n",
        "            results.append((filename, laplacian_var, is_blurred))\n",
        "    return results\n",
        "\n",
        "# 2. Mostrar imágenes en formato grid\n",
        "def show_img_grid(images, titles, grid_size=(3, 3), figsize=(10, 10)):\n",
        "    \"\"\"\n",
        "    Muestra las imágenes en una cuadrícula.\n",
        "\n",
        "    Args:\n",
        "        images (list): Lista de rutas de imágenes.\n",
        "        titles (list): Lista de títulos para cada imagen.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula (filas, columnas).\n",
        "        figsize (tuple): Tamaño de la figura.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(*grid_size, figsize=figsize)\n",
        "    axes = axes.ravel()\n",
        "    for idx, (img_path, title) in enumerate(zip(images, titles)):\n",
        "        if idx >= len(axes):\n",
        "            break\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(title)\n",
        "        axes[idx].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 3. Analizar imágenes borrosas y mostrarlas\n",
        "def analyze_and_move_blurry_images(directory_path, output_directory, threshold=100, grid_size=(3, 3)):\n",
        "    \"\"\"\n",
        "    Analiza las imágenes en un directorio para detectar y mover imágenes borrosas.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Ruta al directorio de imágenes.\n",
        "        output_directory (str): Ruta al directorio de destino para imágenes borrosas.\n",
        "        threshold (float): Umbral de varianza para detectar imágenes borrosas.\n",
        "        grid_size (tuple): Tamaño de la cuadrícula para mostrar imágenes.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Detectar imágenes borrosas\n",
        "    blurry_results = detect_and_move_blurry_images(directory_path, output_directory, threshold)\n",
        "    num_b_blurry = sum(1 for _, _, is_blurred in blurry_results if is_blurred)\n",
        "\n",
        "    # Informe general\n",
        "    print(f\"\\nResumen del análisis:\")\n",
        "    print(f\"Total de imágenes analizadas: {len(blurry_results)}\")\n",
        "    print(f\"Total de imágenes borrosas detectadas y movidas: {num_b_blurry}\")\n",
        "    print(f\"Imágenes nítidas: {len(blurry_results) - num_b_blurry}\")\n",
        "\n",
        "    # Preparar imágenes borrosas para el grid\n",
        "    selected_images = []\n",
        "    titles = []\n",
        "    for filename, var, blurred in blurry_results:\n",
        "        if blurred:  # Solo incluir imágenes borrosas\n",
        "            image_path = os.path.join(output_directory, filename)\n",
        "            selected_images.append(image_path)\n",
        "            titles.append(f\"BORROSA\\nVar: {var:.2f}\")\n",
        "\n",
        "            # Detener si se alcanza el límite del grid\n",
        "            if len(selected_images) >= grid_size[0] * grid_size[1]:\n",
        "                break\n",
        "\n",
        "    # Mostrar imágenes borrosas en formato grid\n",
        "    if selected_images:\n",
        "        show_img_grid(selected_images, titles, grid_size)\n",
        "    else:\n",
        "        print(\"No se encontraron imágenes borrosas para mostrar.\")\n",
        "\n",
        "# Ejecutar el análisis y mover imágenes borrosas\n",
        "threshold = 20  # Ajusta el umbral según sea necesario\n",
        "analyze_and_move_blurry_images(input_dir, output_dir, threshold, grid_size=(3, 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6YnyCCNVnD6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MISMO CODIGO DE CLASIFICACION DE IMAGENES PERO CON EL CONJUNTO DE DATOS\n",
        "/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\n",
        "'''\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "from IPython.display import display  # Importar para mostrar imágenes en Colab\n",
        "\n",
        "# Verificar el contenido del directorio\n",
        "dataset_path = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\"\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise FileNotFoundError(f\"El directorio {dataset_path} no existe. Verifica la ruta.\")\n",
        "\n",
        "# Listar archivos en el directorio\n",
        "files = os.listdir(dataset_path)\n",
        "if len(files) == 0:\n",
        "    raise FileNotFoundError(f\"El directorio {dataset_path} está vacío. Asegúrate de que contiene imágenes.\")\n",
        "\n",
        "# Filtrar solo archivos de imagen\n",
        "image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "if len(image_files) == 0:\n",
        "    raise FileNotFoundError(f\"No se encontraron imágenes en {dataset_path}. Asegúrate de que el directorio contiene imágenes.\")\n",
        "\n",
        "# Elige una imagen aleatoria del conjunto de datos\n",
        "random_image = os.path.join(dataset_path, random.choice(image_files))\n",
        "print(f\"Imagen seleccionada: {random_image}\")\n",
        "\n",
        "# Define la resolución según el modelo\n",
        "model_name = \"VisionTransformer\"  # Especifica el modelo\n",
        "resolution = 224 if model_name.startswith('Mixer') else 384\n",
        "\n",
        "# Carga y redimensiona la imagen\n",
        "img = Image.open(random_image)\n",
        "img = img.resize((resolution, resolution))\n",
        "\n",
        "# Muestra la imagen en el notebook\n",
        "display(img)  # Usar IPython.display para mostrar la imagen en Colab\n",
        "\n",
        "# Predict on a batch with a single item (note very efficient TPU usage...)\n",
        "logits = model.apply({'params': params}, np.array(img) / 128 - 1)\n",
        "\n",
        "preds = np.array(jax.nn.softmax(logits))\n",
        "for idx in preds.argsort()[:-11:-1]:\n",
        "  print(f'{preds[idx]:.5f} : {imagenet_labels[idx]}', end='')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XedLquh21XHW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Configuración del modelo ViT preentrenado\n",
        "model_name = 'ViT-B_32'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = models.vision_transformer.vit_b_32(pretrained=True).to(device)\n",
        "model.eval()  # Modo de evaluación\n",
        "\n",
        "# Transformaciones de las imágenes para adaptarlas al modelo\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Tamaño requerido para ViT\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalización estándar\n",
        "])\n",
        "\n",
        "# Diccionario de clases de ImageNet (1,000 clases)\n",
        "imagenet_classes = {idx: cls for (idx, cls) in enumerate(open('ilsvrc2012_wordnet_lemmas.txt').read().splitlines())}\n",
        "\n",
        "# Configurar directorios\n",
        "input_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppComida\"\n",
        "output_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsApp_web_site\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Procesar imágenes\n",
        "def eliminar_fotos_con_personas(input_dir, output_dir):\n",
        "    for image_name in os.listdir(input_dir):\n",
        "        image_path = os.path.join(input_dir, image_name)\n",
        "        try:\n",
        "            # Cargar y transformar la imagen\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "            # Predicción con el modelo\n",
        "            with torch.no_grad():\n",
        "                outputs = model(img_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "                top5_prob, top5_idx = torch.topk(probabilities, 5)\n",
        "\n",
        "                # Obtener las etiquetas de las clases\n",
        "                top5_classes = [imagenet_classes[idx.item()] for idx in top5_idx]\n",
        "                print(f\"Imagen: {image_name}, Clases: {top5_classes}\")\n",
        "\n",
        "                # Verificar si \"person\" está en las clases top5\n",
        "                if 'plate' in top5_classes:\n",
        "                    shutil.move(image_path, os.path.join(output_dir, image_name))\n",
        "                    print(f\"Comida detectada en {image_name}. Imagen movida.\")\n",
        "                else:\n",
        "                    print(f\"No se detectaron platos en {image_name}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al procesar {image_name}: {e}\")\n",
        "\n",
        "    print(\"Proceso completado.\")\n",
        "\n",
        "# Llamada a la función\n",
        "eliminar_fotos_con_personas(input_dir, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2LWwQBtKdgE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuración del modelo ViT preentrenado\n",
        "model_name = 'ViT-B_32'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = models.vision_transformer.vit_b_32(pretrained=True).to(device)\n",
        "model.eval()  # Modo de evaluación\n",
        "\n",
        "# Transformaciones de las imágenes para adaptarlas al modelo\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Tamaño requerido para ViT\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalización estándar\n",
        "])\n",
        "\n",
        "# Diccionario de clases de ImageNet (1,000 clases)\n",
        "imagenet_classes = {idx: cls for (idx, cls) in enumerate(open('ilsvrc2012_wordnet_lemmas.txt').read().splitlines())}\n",
        "\n",
        "# Configurar directorios\n",
        "input_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\"\n",
        "output_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsApp_web_site\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Procesar imágenes\n",
        "def eliminar_fotos_con_personas(input_dir, output_dir, max_images=30):\n",
        "    count = 0  # Contador para controlar el número de imágenes procesadas\n",
        "    for image_name in os.listdir(input_dir):\n",
        "        if count >= max_images:  # Detener el procesamiento después de max_images\n",
        "            break\n",
        "        image_path = os.path.join(input_dir, image_name)\n",
        "        try:\n",
        "            # Cargar y transformar la imagen\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "            # Predicción con el modelo\n",
        "            with torch.no_grad():\n",
        "                outputs = model(img_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "                top5_prob, top5_idx = torch.topk(probabilities, 5)\n",
        "\n",
        "                # Obtener las etiquetas de las clases\n",
        "                top5_classes = [imagenet_classes[idx.item()] for idx in top5_idx]\n",
        "\n",
        "                # Mostrar la imagen y las clases correspondientes\n",
        "                '''plt.figure(figsize=(6, 6))\n",
        "                plt.imshow(img)\n",
        "                plt.axis('off')'''\n",
        "                plt.title(f\"Imagen: {image_name}\\nClases: {top5_classes}\")\n",
        "                '''plt.show()'''\n",
        "\n",
        "                # Verificar si \"person\" está en las clases top5\n",
        "                if 'web_site' in top5_classes:  # Cambia \"person\" según la clase que buscas\n",
        "                    shutil.move(image_path, os.path.join(output_dir, image_name))\n",
        "                    print(f\"Persona detectada en {image_name}. Imagen movida.\")\n",
        "                else:\n",
        "                    print(f\"No se detectaron personas en {image_name}.\")\n",
        "            count += 1  # Incrementar el contador\n",
        "        except Exception as e:\n",
        "            print(f\"Error al procesar {image_name}: {e}\")\n",
        "\n",
        "    print(\"Proceso completado.\")\n",
        "\n",
        "# Llamada a la función\n",
        "eliminar_fotos_con_personas(input_dir, output_dir, max_images=10000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I80cm3XJKeMn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Modelo preentrenado de YOLOv5\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Directorios\n",
        "# Configurar directorios\n",
        "input_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppImages\"\n",
        "output_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/images/DescargasdeAmazonPhotos/WhatsAppPersonas\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Procesar las imágenes\n",
        "for image_name in os.listdir(input_dir):\n",
        "    image_path = os.path.join(input_dir, image_name)\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        results = model(img)  # Detección de objetos\n",
        "        labels = results.pandas().xyxy[0]['name']  # Etiquetas detectadas\n",
        "\n",
        "        # Verifica si se detectaron personas\n",
        "        if 'person' in labels.values:\n",
        "            shutil.move(image_path, os.path.join(output_dir, image_name))\n",
        "            print(f\"Persona detectada en {image_name}. Imagen movida.\")\n",
        "        else:\n",
        "            print(f\"No se detectaron personas en {image_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {image_name}: {e}\")\n",
        "\n",
        "print(\"Proceso completado.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}