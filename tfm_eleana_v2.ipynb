{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzu48mG4ySTfpXkq4s4GyW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eleanarey/ProgramingPractices/blob/main/tfm_eleana_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "BhtkG3PsSZoY",
        "outputId": "dbfd120b-d64c-4d57-e152-2485befe72c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "[ COPYING DATA FROM GOOGLE DRIVE TO LOCAL COLAB SPACE ]\n",
            "  * GOOGLE DRIVE ALREADY MOUNTED AT /content/drive\n",
            "  * COPYING FILES FROM /content/drive/MyDrive/Colab Notebooks TO ./dataset\n",
            "[ DOWNLOADING OPEN IMAGES DATASET ]\n",
            "Archivo ya existente: /content/drive/MyDrive/Colab Notebooks/dataset/test-annotations-human-imagelabels-boxable.csv\n",
            "Archivo ya existente: /content/drive/MyDrive/Colab Notebooks/dataset/test-images.csv\n",
            "[ DOWNLOADING KAGGLE DATASET (IMAGES) ]\n",
            "Dataset ya descargado: ./kaggle_data/wikipedia-movie-plots.zip\n",
            "Archive:  ./kaggle_data/wikipedia-movie-plots.zip\n",
            "caution: filename not matched:  Notebooks/dataset\n",
            "[ DOWNLOADING KAGGLE DATASET (PDFS) ]\n",
            "403 - Forbidden - Permission 'datasets.get' was denied\n",
            "unzip:  cannot find or open ./kaggle_data/documents-dataset.zip, ./kaggle_data/documents-dataset.zip.zip or ./kaggle_data/documents-dataset.zip.ZIP.\n",
            "[ PROCESSING FILES ]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: './dataset/dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fcea38bb6a63>\u001b[0m in \u001b[0;36m<cell line: 133>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mis_duplicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_duplicate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-fcea38bb6a63>\u001b[0m in \u001b[0;36mdetect_duplicates\u001b[0;34m(file_path, hash_dict)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Función para detectar duplicados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mfile_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_hash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhash_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_hash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-fcea38bb6a63>\u001b[0m in \u001b[0;36mget_file_hash\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_file_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mhasher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './dataset/dataset'"
          ]
        }
      ],
      "source": [
        "# Instalación de bibliotecas necesarias\n",
        "!pip install PyPDF2 kaggle\n",
        "\n",
        "!rm -rf ./dataset  # Eliminar carpeta local si existe\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "import hashlib\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import PyPDF2\n",
        "\n",
        "# Configuración inicial\n",
        "localDataset = False\n",
        "mountPoint = '/content/drive'\n",
        "remotePath = 'MyDrive/Colab Notebooks'\n",
        "localPath = './dataset'\n",
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/dataset'  # Ruta de salida en Google Drive\n",
        "categories = ['imagenes_validas', 'imagenes_invalidas', 'pdfs_validos', 'pdfs_invalidos', 'duplicados']\n",
        "\n",
        "# Configuración para Kaggle\n",
        "kaggle_dataset_images = \"jrobischon/wikipedia-movie-plots\"  # Dataset de ejemplo\n",
        "kaggle_dataset_pdfs = \"lalitharajesh/documents-dataset\"  # Cambiar a un dataset de PDFs\n",
        "kaggle_folder = \"./kaggle_data\"\n",
        "\n",
        "# Descarga desde Open Images (ejemplo limitado para pruebas)\n",
        "open_images_urls = [\n",
        "    \"https://storage.googleapis.com/openimages/2018_04/test/test-annotations-human-imagelabels-boxable.csv\",\n",
        "    \"https://storage.googleapis.com/openimages/2018_04/test/test-images.csv\"\n",
        "]\n",
        "\n",
        "# Función para calcular hash de un archivo (para detectar duplicados)\n",
        "def get_file_hash(file_path):\n",
        "    hasher = hashlib.md5()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        buf = f.read()\n",
        "        hasher.update(buf)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "# Función para detectar duplicados\n",
        "def detect_duplicates(file_path, hash_dict):\n",
        "    file_hash = get_file_hash(file_path)\n",
        "    if file_hash in hash_dict:\n",
        "        return True, hash_dict[file_hash]\n",
        "    hash_dict[file_hash] = file_path\n",
        "    return False, None\n",
        "\n",
        "# Función para validar imágenes\n",
        "def validate_image(image_path):\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            img.verify()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Archivo no válido (imagen): {image_path}, Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Función para validar PDFs\n",
        "def validate_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            if len(reader.pages) > 0:\n",
        "                return True\n",
        "    except Exception as e:\n",
        "        print(f\"Archivo no válido (PDF): {pdf_path}, Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Función para descargar y validar Open Images Dataset\n",
        "def download_open_images(output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    for url in open_images_urls:\n",
        "        file_name = url.split(\"/\")[-1]\n",
        "        save_path = os.path.join(output_folder, file_name)\n",
        "        if not os.path.exists(save_path):  # Validar si el archivo ya existe\n",
        "            response = requests.get(url, stream=True)\n",
        "            if response.status_code == 200:\n",
        "                with open(save_path, \"wb\") as file:\n",
        "                    shutil.copyfileobj(response.raw, file)\n",
        "                print(f\"Descargado: {save_path}\")\n",
        "            else:\n",
        "                print(f\"Error al descargar {url}\")\n",
        "        else:\n",
        "            print(f\"Archivo ya existente: {save_path}\")\n",
        "\n",
        "# Función para descargar y procesar Kaggle Datasets\n",
        "def download_kaggle_dataset(kaggle_dataset, output_folder):\n",
        "    os.makedirs(kaggle_folder, exist_ok=True)\n",
        "    zip_path = os.path.join(kaggle_folder, f\"{kaggle_dataset.split('/')[-1]}.zip\")\n",
        "    if not os.path.exists(zip_path):  # Validar si el dataset ya fue descargado\n",
        "        !kaggle datasets download -d {kaggle_dataset} -p {kaggle_folder}\n",
        "    else:\n",
        "        print(f\"Dataset ya descargado: {zip_path}\")\n",
        "    !unzip -o {zip_path} -d {output_folder}\n",
        "\n",
        "# Copiar datos desde Google Drive\n",
        "if not localDataset:\n",
        "    print('[ COPYING DATA FROM GOOGLE DRIVE TO LOCAL COLAB SPACE ]')\n",
        "    if os.path.isdir(mountPoint):\n",
        "        print(f'  * GOOGLE DRIVE ALREADY MOUNTED AT {mountPoint}')\n",
        "    else:\n",
        "        print(f'  * MOUNTING GOOGLE DRIVE AT {mountPoint}')\n",
        "        drive.mount(mountPoint)\n",
        "\n",
        "    remoteDir = os.path.join(mountPoint, remotePath)\n",
        "    if not os.path.exists(remoteDir):\n",
        "        print(f'  * Remote directory {remoteDir} does not exist. Creating it now.')\n",
        "        os.makedirs(remoteDir, exist_ok=True)\n",
        "\n",
        "    if os.path.isdir(localPath):\n",
        "        print(f'  * LOCAL PATH {localPath} ALREADY EXISTS.')\n",
        "    else:\n",
        "        print(f'  * COPYING FILES FROM {remoteDir} TO {localPath}')\n",
        "        shutil.copytree(remoteDir, localPath)\n",
        "\n",
        "# Descargar y procesar Open Images Dataset\n",
        "print('[ DOWNLOADING OPEN IMAGES DATASET ]')\n",
        "download_open_images(output_folder)\n",
        "\n",
        "# Descargar y procesar Kaggle Dataset de Imágenes\n",
        "print('[ DOWNLOADING KAGGLE DATASET (IMAGES) ]')\n",
        "download_kaggle_dataset(kaggle_dataset_images, output_folder)\n",
        "\n",
        "# Descargar y procesar Kaggle Dataset de PDFs\n",
        "print('[ DOWNLOADING KAGGLE DATASET (PDFS) ]')\n",
        "download_kaggle_dataset(kaggle_dataset_pdfs, output_folder)\n",
        "\n",
        "# Procesar archivos locales y duplicados\n",
        "print('[ PROCESSING FILES ]')\n",
        "hash_dict = {}\n",
        "\n",
        "for file_name in os.listdir(localPath):\n",
        "    file_path = os.path.join(localPath, file_name)\n",
        "    is_duplicate, original_path = detect_duplicates(file_path, hash_dict)\n",
        "\n",
        "    if is_duplicate:\n",
        "        print(f\"Duplicado detectado: {file_path} (original: {original_path})\")\n",
        "        organize_file(file_path, 'duplicados', output_folder)\n",
        "    elif file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "        if validate_image(file_path):\n",
        "            organize_file(file_path, 'imagenes_validas', output_folder)\n",
        "        else:\n",
        "            organize_file(file_path, 'imagenes_invalidas', output_folder)\n",
        "    elif file_name.lower().endswith('.pdf'):\n",
        "        if validate_pdf(file_path):\n",
        "            organize_file(file_path, 'pdfs_validos', output_folder)\n",
        "        else:\n",
        "            organize_file(file_path, 'pdfs_invalidos', output_folder)\n",
        "\n",
        "print('[ DONE ]')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración para Kaggle\n",
        "kaggle_dataset = \"ajaypalsinghlo/world-bank-invoices\"  # Dataset con PDFs\n",
        "kaggle_folder = \"./kaggle_data\"\n",
        "\n",
        "# Función para descargar y procesar Kaggle Datasets\n",
        "def download_kaggle_dataset(kaggle_dataset, output_folder):\n",
        "    os.makedirs(kaggle_folder, exist_ok=True)\n",
        "    !kaggle datasets download -d {kaggle_dataset} -p {kaggle_folder}\n",
        "    !unzip -o {kaggle_folder}/*.zip -d {output_folder}\n"
      ],
      "metadata": {
        "id": "-wVrLbKIcEN2"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}